{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f9a9d8-cc2b-4a48-be42-f71374c970d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Notebook 3\n",
    "# Forecasting Congestion Income ‚Äî Model Training & Evaluation\n",
    "# ================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "print(\"‚ö° Notebook 3 ‚Äî Forecasting Congestion Income (DK2)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d009a716-fd90-4203-be14-f07a68b67a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# 1. Load engineered feature dataset\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "FEATURE_PATH = Path(\"data/processed/features_congestion_income.parquet\")\n",
    "\n",
    "if not FEATURE_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Feature dataset not found at: {FEATURE_PATH}\\n\"\n",
    "        \"‚Üí Run Notebook 2 first.\"\n",
    "    )\n",
    "\n",
    "df = pd.read_parquet(FEATURE_PATH)\n",
    "\n",
    "print(f\"‚úî Loaded feature dataset: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "print(f\"üïí Time range: {df.index.min()} ‚Üí {df.index.max()}\")\n",
    "\n",
    "display(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c60b73-9e9d-4a57-9cfe-f1b89216c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# 2. Define forecasting horizon\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "HORIZON = 1   # 1-step ahead = 15 minutes\n",
    "df[\"target\"] = df[\"RevenueEUR\"].shift(-HORIZON)\n",
    "\n",
    "# Drop final rows where target is missing\n",
    "df = df.dropna(subset=[\"target\"])\n",
    "\n",
    "print(\"‚úî Target column created.\")\n",
    "df[[\"RevenueEUR\", \"target\"]].head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab05433d-9b06-4344-960c-dffb6493d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# 3. Train/Test Split (no shuffling!)\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "split_ratio = 0.8\n",
    "split_idx = int(len(df) * split_ratio)\n",
    "\n",
    "train = df.iloc[:split_idx].copy()\n",
    "test  = df.iloc[split_idx:].copy()\n",
    "\n",
    "X_train = train.drop(columns=[\"target\"])\n",
    "y_train = train[\"target\"]\n",
    "X_test  = test.drop(columns=[\"target\"])\n",
    "y_test  = test[\"target\"]\n",
    "\n",
    "print(f\"‚úî Train size: {len(train)} rows\")\n",
    "print(f\"‚úî Test size:  {len(test)} rows\")\n",
    "print(f\"Split at index: {split_idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516557d6-51ff-4d36-87dd-c618d65ab9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# 4. Baseline Models\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "def naive_forecast(series):\n",
    "    return series.shift(1)\n",
    "\n",
    "def seasonal_naive(series, lag_steps=96):  # 1 day = 96 √ó 15min\n",
    "    return series.shift(lag_steps)\n",
    "\n",
    "def rolling_mean_forecast(series, window=24):  # 6 hours\n",
    "    return series.rolling(window).mean()\n",
    "\n",
    "y_pred_naive = naive_forecast(train[\"target\"]).shift(-1).iloc[split_idx:]\n",
    "y_pred_seasonal = seasonal_naive(train[\"target\"]).shift(-1).iloc[split_idx:]\n",
    "y_pred_roll = rolling_mean_forecast(train[\"target\"]).shift(-1).iloc[split_idx:]\n",
    "\n",
    "print(\"‚úî Baselines computed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a72c54-8358-4e47-a908-4086d5683d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# 5. Evaluation Metrics\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def rmse(y, x):\n",
    "    return np.sqrt(mean_squared_error(y, x))\n",
    "\n",
    "def mape(y, x):\n",
    "    return np.mean(np.abs((y - x) / y)) * 100\n",
    "\n",
    "def mase(y_true, y_pred, training_series):\n",
    "    naive = np.abs(training_series.diff()).mean()\n",
    "    return np.mean(np.abs(y_true - y_pred)) / naive\n",
    "\n",
    "def evaluate(y_true, y_pred, name):\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    rmse_val = rmse(y_true, y_pred)\n",
    "    mape_val = mape(y_true, y_pred)\n",
    "    mase_val = mase(y_true, y_pred, y_train)\n",
    "\n",
    "    print(f\"\\nüìä {name} Performance\")\n",
    "    print(f\"MAE:  {mae:,.2f}\")\n",
    "    print(f\"RMSE: {rmse_val:,.2f}\")\n",
    "    print(f\"MAPE: {mape_val:,.2f}%\")\n",
    "    print(f\"MASE: {mase_val:,.2f}\")\n",
    "\n",
    "    return mae, rmse_val, mape_val, mase_val\n",
    "\n",
    "baseline_results = {}\n",
    "\n",
    "baseline_results[\"Naive\"] = evaluate(y_test, y_pred_naive, \"Naive\")\n",
    "baseline_results[\"Seasonal Naive\"] = evaluate(y_test, y_pred_seasonal, \"Seasonal Naive\")\n",
    "baseline_results[\"Rolling Mean\"] = evaluate(y_test, y_pred_roll, \"Rolling Mean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c565bf-0ec2-44e0-9ae4-f4ad965311d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# 6. Random Forest Regressor\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=12,\n",
    "    min_samples_split=5,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "rf_results = evaluate(y_test, y_pred_rf, \"Random Forest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3156cc68-7d34-447d-98e2-be2e1a06ffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# 7. XGBoost Model\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "\n",
    "    xgb = XGBRegressor(\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=8,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.9,\n",
    "        eval_metric=\"rmse\"\n",
    "    )\n",
    "\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred_xgb = xgb.predict(X_test)\n",
    "    xgb_results = evaluate(y_test, y_pred_xgb, \"XGBoost\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è XGBoost not installed. Skipping this model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c248cfd-ff7f-44b8-92af-182ee1ba087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# 8. Model Comparison Summary\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"Naive\": baseline_results[\"Naive\"],\n",
    "    \"Seasonal Naive\": baseline_results[\"Seasonal Naive\"],\n",
    "    \"Rolling Mean\": baseline_results[\"Rolling Mean\"],\n",
    "    \"Random Forest\": rf_results,\n",
    "}, index=[\"MAE\", \"RMSE\", \"MAPE\", \"MASE\"])\n",
    "\n",
    "display(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f003db-d17e-4612-a783-031471b75ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# 9. Residual Diagnostics\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "residuals = y_test - y_pred_rf\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
    "\n",
    "sns.histplot(residuals, ax=axes[0], kde=True)\n",
    "axes[0].set_title(\"Residual Distribution\")\n",
    "\n",
    "sns.scatterplot(x=y_pred_rf, y=residuals, ax=axes[1])\n",
    "axes[1].set_title(\"Residual vs Predicted\")\n",
    "\n",
    "sns.lineplot(x=residuals.index, y=residuals, ax=axes[2])\n",
    "axes[2].set_title(\"Residual Time Series\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc0c69e-9aa1-4435-a8ff-20b474756ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# 10. True vs Predicted Plot\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "fig = px.line(\n",
    "    x=y_test.index,\n",
    "    y=[y_test.values, y_pred_rf],\n",
    "    labels={\"x\": \"Time\", \"value\": \"Congestion Income (EUR)\"},\n",
    "    title=\"True vs Predicted (Random Forest)\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    legend=dict(title=\"Series\", itemsizing=\"constant\"),\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023ac40d-8221-43d0-aca9-8dd0a45cd766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# 11. Feature Importance\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "importances = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "importances = importances.sort_values(ascending=False)\n",
    "\n",
    "fig = px.bar(\n",
    "    importances.head(20),\n",
    "    title=\"Top 20 Feature Importances (Random Forest)\"\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1848ccd9-aad5-4c82-a7af-62798c223b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# 12. Save Model + Forecast Outputs\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "import joblib\n",
    "\n",
    "MODEL_DIR = Path(\"models\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "joblib.dump(rf, MODEL_DIR / \"rf_model.pkl\")\n",
    "y_test.to_frame(\"true\").assign(pred_rf=y_pred_rf).to_parquet(\n",
    "    Path(\"data/processed/forecast_results.parquet\")\n",
    ")\n",
    "\n",
    "print(\"‚úî Model and forecast results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afc9397-fd3c-4a84-815f-b56c3b7007a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# 13. LLM-Assisted Forecast Interpretation\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "OLLAMA_URL = os.getenv(\"OLLAMA_URL\", \"http://localhost:11434\")\n",
    "OLLAMA_MODEL = os.getenv(\"OLLAMA_MODEL\", \"llama3.1:8b-instruct-q4_0\")\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are a senior electricity-market analyst.\n",
    "\n",
    "Write an interpretive summary of the forecasting model performance:\n",
    "- how well the model captures daily structure\n",
    "- when it fails (e.g., spikes, ramps, volatility bursts)\n",
    "- what the residuals say about model bias\n",
    "- how feature importance aligns with power-system behavior\n",
    "- compare model vs naive baselines\n",
    "\n",
    "Keep it concise and insightful.\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    response = requests.post(\n",
    "        f\"{OLLAMA_URL}/api/generate\",\n",
    "        json={\"model\": OLLAMA_MODEL, \"prompt\": prompt, \"stream\": False}\n",
    "    )\n",
    "    text = response.json().get(\"response\", \"\").strip()\n",
    "\n",
    "    display(Markdown(\"### ü§ñ LLM Forecast Analysis\\n\" + text))\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è LLM unavailable:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2878c939-0ce9-4ebe-b4d9-a974bed54f37",
   "metadata": {},
   "source": [
    "## üìò Notebook 3 Summary ‚Äî Forecasting\n",
    "\n",
    "This notebook implemented:\n",
    "- Horizon definition (15-min ahead)\n",
    "- Train/test split with time integrity\n",
    "- Baseline forecasts (naive, seasonal naive, rolling mean)\n",
    "- ML models (Random Forest, XGBoost)\n",
    "- Evaluation (MAE, RMSE, MAPE, MASE)\n",
    "- Residual diagnostics\n",
    "- Feature importance\n",
    "- Scenario plots\n",
    "- LLM-assisted model interpretation\n",
    "- Model & forecast saving\n",
    "\n",
    "Proceed to **Notebook 4 ‚Äî Multi-Step Forecasting & Model Optimization**.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Energy Platform (venv)",
   "language": "python",
   "name": "energy-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
